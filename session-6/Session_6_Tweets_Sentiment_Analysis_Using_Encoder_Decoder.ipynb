{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session #6: Tweets Sentiment Analysis Using Encoder-Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mGP2Ockq_rF"
      },
      "source": [
        "## Encoder-Decoder Architecture \n",
        "Dataset: Tweets | Task : Sentiment Analysis\n",
        "\n",
        "*Submitted: Pavithra Solai* on June 10 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEs6dV6etDIM"
      },
      "source": [
        "#### Load the Datasets into DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQBzFa3oTT8V",
        "outputId": "aea3e8df-e835-4f50-a05a-ef281b55caab"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "#from torchtext import data \n",
        "from torchtext.legacy import data\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc5375009b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3tB8N-WSYfu",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "26aa09a8-d451-4afb-f6ee-7ef453711bb5"
      },
      "source": [
        "#Upload tweets csv file\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d131fa50-ebe5-43af-ace7-4b099579fd03\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d131fa50-ebe5-43af-ace7-4b099579fd03\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving augmented_tweets_train.csv to augmented_tweets_train.csv\n",
            "Saving train_tweets.csv to train_tweets.csv\n",
            "Saving tweets.csv to tweets.csv\n",
            "Saving valid_tweets.csv to valid_tweets.csv\n",
            "User uploaded file \"augmented_tweets_train.csv\" with length 282397 bytes\n",
            "User uploaded file \"train_tweets.csv\" with length 117565 bytes\n",
            "User uploaded file \"tweets.csv\" with length 160041 bytes\n",
            "User uploaded file \"valid_tweets.csv\" with length 20312 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfCRIH61TDFX",
        "outputId": "fb830631-66db-4173-efca-5010d0ec945a"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('train_tweets.csv')\n",
        "print(\"Length of train dataset: \",len(df_train))\n",
        "#df_train = pd.read_csv('augmented_tweets_train.csv')\n",
        "#print(\"Length of augmented train dataset: \",len(df_train))\n",
        "df_valid = pd.read_csv('valid_tweets.csv')\n",
        "print(\"Length of Validation dataset: \",len(df_valid))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train dataset:  1159\n",
            "Length of Validation dataset:  205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFjxdokKTNQm"
      },
      "source": [
        "df_train[\"tweets\"]=df_train[\"tweets\"].astype(str)\n",
        "df_train[\"labels\"] = df_train[\"labels\"].astype(int)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTegPnNBTO8M",
        "outputId": "e19720d0-ee14-4e33-8876-955a56e9193e"
      },
      "source": [
        "df_train.labels.value_counts()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    791\n",
              "1    299\n",
              "2     69\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEPor7GN9kvs"
      },
      "source": [
        "#Shuffling the dataset - Useful for Data augmentation\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df_train = shuffle(df_train)\n",
        "df_train.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmOo_q5ornpv"
      },
      "source": [
        "#### Create a PyTorch Dataset\n",
        "\n",
        "- Associate the data.Field and data.LabelField to Tweets and Labels\n",
        "- We use Spacy for tokenization\n",
        "- fields is a list of tuples that associate DataFrame columns to data.Field and data.LabelField"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMs7LqUwTRXx"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)\n",
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "mcIgvjoQrrzB",
        "outputId": "52a70809-1a4f-4e60-9d45-c7b2f04cdd16"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df_train[:10]"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>444</td>\n",
              "      <td>Lady well then who s the president</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>849</td>\n",
              "      <td>Think the GOP is engaged in a War on Women Why is Obama meeting with Women s worst enemy the Muslim Bro. tomorrow at OUR whitehouse</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>778</td>\n",
              "      <td>LOOOOOOOOOOOOOOOOOOOOOOOOOOOOL This is why i rate obama vsOYFhSa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>894</td>\n",
              "      <td>Obama in Boca saywhatttt</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>947</td>\n",
              "      <td>Obama will portray Romney as a rich white guy outta touch w the working class whos policies are similar to his so why not keep the hip cat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>940</td>\n",
              "      <td>We want a president with a spine not a president with fecklessness. America can do better than Obama. resist44 tcot if you agree</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>739</td>\n",
              "      <td>Harry Styles describe a Michelle Obama como una mujer muy atractiva. OBAMA ESCONDE A TU ESPOSA Y A TUS HIJOS STYLES VIENE EN CAMINO.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>776</td>\n",
              "      <td>LIMBAUGH Obama Puts Out Figurative Bounty on Supreme Court... Z552mkRl</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>606</td>\n",
              "      <td>Major Obama Donor Accused Of Fraud I hope no one vets me. I donated 5 and one time I stole a bracelet from Target. 91ecaJAE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>703</td>\n",
              "      <td>Righties call Pres. Obama a thug and bully for comments on health care law hearings. Comment on FB or tweet so we can share on edshow</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... labels\n",
              "0         444  ...      1\n",
              "1         849  ...      0\n",
              "2         778  ...      0\n",
              "3         894  ...      0\n",
              "4         947  ...      2\n",
              "5         940  ...      1\n",
              "6         739  ...      0\n",
              "7         776  ...      1\n",
              "8         606  ...      0\n",
              "9         703  ...      0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7OrDLObscll"
      },
      "source": [
        "**data.Example** shows how each record of the Dataset will be read from the DataFrames. We create train and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZypmmKTa3X"
      },
      "source": [
        "\n",
        "example = [data.Example.fromlist([df_train.tweets[i],df_train.labels[i]], fields) for i in range(df_train.shape[0])] \n",
        "twitter_train_dataset = data.Dataset(example, fields)\n",
        "\n",
        "example = [data.Example.fromlist([df_valid.tweets[i],df_valid.labels[i]], fields) for i in range(df_valid.shape[0])] \n",
        "twitter_valid_dataset = data.Dataset(example, fields)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdiRgkswsjFz"
      },
      "source": [
        "Example of the Train Dataset for Tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNqJ8QNqTiX1",
        "outputId": "db0f1ed6-c836-447f-c940-47c5f2bcb334"
      },
      "source": [
        "vars(twitter_train_dataset.examples[5])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 1,\n",
              " 'tweets': ['We',\n",
              "  'want',\n",
              "  'a',\n",
              "  'president',\n",
              "  'with',\n",
              "  'a',\n",
              "  'spine',\n",
              "  'not',\n",
              "  'a',\n",
              "  'president',\n",
              "  'with',\n",
              "  'fecklessness',\n",
              "  '.',\n",
              "  'America',\n",
              "  'can',\n",
              "  'do',\n",
              "  'better',\n",
              "  'than',\n",
              "  'Obama',\n",
              "  '.',\n",
              "  'resist44',\n",
              "  'tcot',\n",
              "  'if',\n",
              "  'you',\n",
              "  'agree']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__vl1nYxsnAR"
      },
      "source": [
        "#### Building The Vocabulary based on Spacy Tokens\n",
        "\n",
        "We build the vocab based on the distinct number of non-repetitive tokens and store it in Pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHZdCHH9TkMW",
        "outputId": "3f633aad-cd95-440c-ea83-1e4e446ea389"
      },
      "source": [
        "Tweet.build_vocab(twitter_train_dataset)\n",
        "Label.build_vocab(twitter_train_dataset)\n",
        "\n",
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_iterator = data.BucketIterator(twitter_train_dataset, batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)\n",
        "import os, pickle\n",
        "with open('train_tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4236\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1050), ('.', 781), ('the', 528), ('to', 403), ('s', 307), ('of', 242), ('a', 233), ('you', 219), ('with', 214), ('is', 208)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9emIYbpTxtP"
      },
      "source": [
        "Tweet.build_vocab(twitter_valid_dataset)\n",
        "Label.build_vocab(twitter_valid_dataset)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "valid_iterator = data.BucketIterator(twitter_valid_dataset, batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)\n",
        "\n",
        "with open('valid_tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYasROJo-Z3J"
      },
      "source": [
        "# For printing tensors - This makes it look legible\n",
        "torch.set_printoptions(profile=\"short\", precision=2, sci_mode=False, linewidth=150)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20UBgQq-tM_2"
      },
      "source": [
        "#### Encoder Decoder Model Architecture\n",
        "\n",
        "Here we use a multi-step LSTM cell to simulate a encoder that reads words from a sentence one by one and create feature-rich embedding (h_t) which is set to a single-step LSTM cell that acts as a decoder. \n",
        "\n",
        "Using the Decoder's outputs, we send it to a Fully connected layer and then to softmax followed by Cross Entropy loss\n",
        "\n",
        "**Points to Note**\n",
        "1. The embedding tensor has all the embeddings of the tokens in a sentence for a given a batch of sentences\n",
        "2. We iterate over each token embedding and send it to a LSTM cell. i.e. For a batch of 32 sentences, we send the 1st token of all the 32 sentences, use the hidden layer (h_1) output from that step and feed the 2nd word along with (h_1) and so on and so forth\n",
        "3. When we start with the first token, the hidden and cell state have to be randomly initialized.\n",
        "4. This is done for both Encoder and Decoder\n",
        "5. For Decoder, we need to set a hidden layer dimension and in my case, I have used 150 for hidden_dim for Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Qm0hzwTzIw"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_enc_dim, hidden_dec_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()     \n",
        "        self.hidden_dim = hidden_enc_dim\n",
        "        self.hidden_dec_dim = hidden_dec_dim     \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # Encoder-Decoder Architecture\n",
        "        self.encoder = nn.LSTMCell(embedding_dim, self.hidden_dim)\n",
        "\n",
        "        self.decoder = nn.LSTMCell(self.hidden_dim, self.hidden_dec_dim)\n",
        "     \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(150, output_dim)\n",
        "\n",
        "             \n",
        "    def forward(self, text, text_lengths, verbatim=False):\n",
        "        \n",
        "        # Input is batch of text vocab indices - 32 x longest_sentence_length\n",
        "        # text = [batch size, sentence length]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim] = [32, longest_sentence_length_in_batch, 300]\n",
        "\n",
        "        ########## ENCODER ########\n",
        "\n",
        "        batch_size = embedded.size()[0]\n",
        "      \n",
        "        hidden = torch.randn(batch_size, self.hidden_dim,device=\"cuda\", requires_grad=True)\n",
        "        cell_state = torch.randn(batch_size, self.hidden_dim, device=\"cuda\", requires_grad=True)\n",
        "        #hidden = [32,100]\n",
        "        #cell_state = [32,100]\n",
        "\n",
        "        sentence_len = text.size()[1]\n",
        "        if verbatim:\n",
        "          print(\"Length of the sentence : \",sentence_len)\n",
        "\n",
        "        for i in range(0,sentence_len):\n",
        "          if verbatim:\n",
        "            print(f\"\\nFeeding word %d of the sentence with length %d \"%((i+1),sentence_len))\n",
        "\n",
        "          hidden, cell_state = self.encoder(embedded[:,i,:],(hidden, cell_state))\n",
        "\n",
        "          if verbatim:\n",
        "            print(f\"\\nHidden state -- h_%d -- for batch size of %d: \\n\" % ((i+1),batch_size))\n",
        "            print(hidden, hidden.size())\n",
        "\n",
        "        output_encoder =  hidden #Last Hidden Layer #[32 x 100]\n",
        "        if verbatim:\n",
        "          print(\"\\nOutput of Encoder : \\n******************\\n \", hidden, hidden.size())\n",
        "        \n",
        "\n",
        "        ######### DECODER ##########\n",
        "        hidden = torch.randn(batch_size, self.hidden_dec_dim,device=\"cuda\", requires_grad=True)\n",
        "        cell_state = torch.randn(batch_size, self.hidden_dec_dim, device=\"cuda\", requires_grad=True)\n",
        "        #hidden = [32,150]\n",
        "        #cell_state = [32,150]\n",
        "\n",
        "        output_decoder, cell_decoder = self.decoder(output_encoder,(hidden, cell_state)) #[32 x 150]\n",
        "        if verbatim:\n",
        "          print(\"\\nOutput of Decoder : \\n******************\\n\",output_decoder, output_decoder.size())\n",
        "        \n",
        "        \n",
        "        dense_outputs = self.fc(output_decoder)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs, dim=1)\n",
        "           \n",
        "        return output\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU6G1PiUt2Sl"
      },
      "source": [
        "\"\"\n",
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes_encoder = 100\n",
        "num_hidden_nodes_decoder = 150\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "dropout = 0.2\n",
        "batch_size = 32\n",
        "\n",
        "# Instantiate the model\n",
        "model = EncoderDecoder(size_of_vocab, \n",
        "                       embedding_dim, \n",
        "                       num_hidden_nodes_encoder, \n",
        "                       num_hidden_nodes_decoder, \n",
        "                       num_output_nodes, \n",
        "                       num_layers, \n",
        "                       dropout = dropout)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te0UIStAuCgm",
        "outputId": "c4805383-5ca6-408c-d6f9-ef79c28e27d5"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderDecoder(\n",
            "  (embedding): Embedding(1368, 300)\n",
            "  (encoder): LSTMCell(300, 100)\n",
            "  (decoder): LSTMCell(100, 150)\n",
            "  (fc): Linear(in_features=150, out_features=3, bias=True)\n",
            ")\n",
            "The model has 722,853 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seU8TILluE3g"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh0M67pVwKBV"
      },
      "source": [
        "#### Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hbX5mtiuJF2"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGz2BJq9uKka"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoVXq3IbuMRK",
        "outputId": "dfe23ce6-2159-42d2-db5d-25d03afecfc0"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 25\n",
        "best_valid_loss = float('inf')\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracy.append(train_acc)\n",
        "\n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    val_losses.append(valid_loss)\n",
        "    val_accuracy.append(valid_acc)\n",
        "\n",
        "\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'Epoch {epoch+1} | Time Taken: {(time.time() - start_time):.2f}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')\n",
        "     "
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | Time Taken: 0.30s\n",
            "\tTrain Loss: 1.083 | Train Acc: 49.29%\n",
            "\t Val. Loss: 1.074 |  Val. Acc: 56.11% \n",
            "\n",
            "Epoch 2 | Time Taken: 0.28s\n",
            "\tTrain Loss: 1.061 | Train Acc: 61.31%\n",
            "\t Val. Loss: 1.046 |  Val. Acc: 68.99% \n",
            "\n",
            "Epoch 3 | Time Taken: 0.28s\n",
            "\tTrain Loss: 1.017 | Train Acc: 67.05%\n",
            "\t Val. Loss: 0.983 |  Val. Acc: 68.75% \n",
            "\n",
            "Epoch 4 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.948 | Train Acc: 68.65%\n",
            "\t Val. Loss: 0.912 |  Val. Acc: 70.98% \n",
            "\n",
            "Epoch 5 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.890 | Train Acc: 68.74%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 71.88% \n",
            "\n",
            "Epoch 6 | Time Taken: 0.29s\n",
            "\tTrain Loss: 0.869 | Train Acc: 68.82%\n",
            "\t Val. Loss: 0.853 |  Val. Acc: 71.43% \n",
            "\n",
            "Epoch 7 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.858 | Train Acc: 69.08%\n",
            "\t Val. Loss: 0.853 |  Val. Acc: 70.98% \n",
            "\n",
            "Epoch 8 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.850 | Train Acc: 69.58%\n",
            "\t Val. Loss: 0.845 |  Val. Acc: 70.98% \n",
            "\n",
            "Epoch 9 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.846 | Train Acc: 70.26%\n",
            "\t Val. Loss: 0.844 |  Val. Acc: 70.98% \n",
            "\n",
            "Epoch 10 | Time Taken: 0.30s\n",
            "\tTrain Loss: 0.842 | Train Acc: 71.36%\n",
            "\t Val. Loss: 0.836 |  Val. Acc: 71.43% \n",
            "\n",
            "Epoch 11 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.838 | Train Acc: 71.44%\n",
            "\t Val. Loss: 0.828 |  Val. Acc: 70.33% \n",
            "\n",
            "Epoch 12 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.834 | Train Acc: 72.45%\n",
            "\t Val. Loss: 0.825 |  Val. Acc: 71.22% \n",
            "\n",
            "Epoch 13 | Time Taken: 0.29s\n",
            "\tTrain Loss: 0.831 | Train Acc: 73.13%\n",
            "\t Val. Loss: 0.819 |  Val. Acc: 72.77% \n",
            "\n",
            "Epoch 14 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.830 | Train Acc: 73.64%\n",
            "\t Val. Loss: 0.816 |  Val. Acc: 73.01% \n",
            "\n",
            "Epoch 15 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.828 | Train Acc: 74.40%\n",
            "\t Val. Loss: 0.810 |  Val. Acc: 74.35% \n",
            "\n",
            "Epoch 16 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.826 | Train Acc: 74.48%\n",
            "\t Val. Loss: 0.800 |  Val. Acc: 76.79% \n",
            "\n",
            "Epoch 17 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.824 | Train Acc: 75.24%\n",
            "\t Val. Loss: 0.803 |  Val. Acc: 77.68% \n",
            "\n",
            "Epoch 18 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.823 | Train Acc: 75.07%\n",
            "\t Val. Loss: 0.803 |  Val. Acc: 77.03% \n",
            "\n",
            "Epoch 19 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.820 | Train Acc: 75.49%\n",
            "\t Val. Loss: 0.790 |  Val. Acc: 77.47% \n",
            "\n",
            "Epoch 20 | Time Taken: 0.29s\n",
            "\tTrain Loss: 0.819 | Train Acc: 75.66%\n",
            "\t Val. Loss: 0.792 |  Val. Acc: 77.92% \n",
            "\n",
            "Epoch 21 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.811 | Train Acc: 76.51%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 79.26% \n",
            "\n",
            "Epoch 22 | Time Taken: 0.27s\n",
            "\tTrain Loss: 0.807 | Train Acc: 76.59%\n",
            "\t Val. Loss: 0.783 |  Val. Acc: 79.70% \n",
            "\n",
            "Epoch 23 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.801 | Train Acc: 76.85%\n",
            "\t Val. Loss: 0.780 |  Val. Acc: 79.26% \n",
            "\n",
            "Epoch 24 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.792 | Train Acc: 77.69%\n",
            "\t Val. Loss: 0.770 |  Val. Acc: 80.15% \n",
            "\n",
            "Epoch 25 | Time Taken: 0.28s\n",
            "\tTrain Loss: 0.786 | Train Acc: 78.11%\n",
            "\t Val. Loss: 0.764 |  Val. Acc: 79.70% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0wYMLtLuw8-"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./valid_tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor, verbatim=True)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008u_TTcwQaV"
      },
      "source": [
        "#### Hidden Layer States Along With Output of Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFjR07I-w5JN",
        "outputId": "22adf87d-374e-490a-b0d3-dda5b6e0fbec"
      },
      "source": [
        "sentiment = classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")\n",
        "print(\"Sentiment Classified as \" + sentiment)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the sentence :  15\n",
            "\n",
            "Feeding word 1 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_1 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.22, -0.55, -0.15, -0.35, -0.05, -0.13,  0.15,  0.19, -0.09,  0.50, -0.20, -0.31,  0.37, -0.38, -0.40, -0.20,  0.31, -0.45,  0.18,  0.07,\n",
            "          0.36, -0.68,  0.47,  0.36, -0.03,  0.26, -0.46,  0.37, -0.26, -0.42,  0.26,  0.04,  0.02,  0.18,  0.09,  0.02,  0.20, -0.09,  0.16, -0.03,\n",
            "          0.36, -0.07, -0.00, -0.36, -0.36, -0.06, -0.14, -0.21, -0.02, -0.12,  0.50, -0.16,  0.03, -0.03,  0.02, -0.19, -0.06,  0.01, -0.02, -0.09,\n",
            "         -0.17, -0.45, -0.16, -0.05,  0.13,  0.27,  0.45, -0.07,  0.08,  0.03, -0.12,  0.01,  0.16, -0.09,  0.17, -0.15, -0.46,  0.05, -0.12, -0.23,\n",
            "          0.25,  0.46, -0.27,  0.35, -0.02, -0.04, -0.03, -0.05,  0.06,  0.09, -0.10, -0.52,  0.04,  0.53, -0.25,  0.45,  0.04, -0.04,  0.20,  0.01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 2 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_2 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.67, -0.76, -0.64, -0.79, -0.76, -0.20,  0.64,  0.79, -0.67,  0.08, -0.42,  0.14,  0.65,  0.36, -0.63, -0.55, -0.09, -0.84,  0.58, -0.26,\n",
            "         -0.32, -0.84,  0.32,  0.68, -0.58,  0.59, -0.76,  0.67, -0.36,  0.08,  0.56, -0.50,  0.57,  0.74,  0.14, -0.10, -0.41,  0.55,  0.60, -0.28,\n",
            "          0.10, -0.05, -0.23,  0.27, -0.18,  0.34, -0.01, -0.64,  0.39, -0.70,  0.07,  0.27, -0.54,  0.44, -0.52, -0.61, -0.05,  0.54, -0.34, -0.63,\n",
            "         -0.66, -0.55,  0.38,  0.16,  0.01,  0.66, -0.38, -0.03, -0.43, -0.19, -0.62,  0.57,  0.50,  0.48, -0.28,  0.12, -0.75, -0.31,  0.01, -0.87,\n",
            "          0.78,  0.83,  0.33, -0.40,  0.18, -0.66,  0.17, -0.67,  0.23,  0.70, -0.58, -0.26,  0.72,  0.11, -0.23,  0.77,  0.67,  0.26, -0.27,  0.24]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 3 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_3 -- for batch size of 1: \n",
            "\n",
            "tensor([[     0.90,     -0.90,     -0.81,     -0.93,     -0.90,      0.20,      0.86,      0.94,     -0.91,     -0.69,     -0.76,      0.38,\n",
            "              0.56,      0.82,     -0.80,     -0.75,     -0.67,     -0.95,      0.84,     -0.36,     -0.78,     -0.90,      0.40,      0.82,\n",
            "             -0.85,      0.82,     -0.91,      0.88,     -0.76,      0.74,      0.82,     -0.86,      0.85,      0.91,      0.00,     -0.28,\n",
            "             -0.83,      0.88,      0.86,      0.09,     -0.66,     -0.05,     -0.64,      0.74,     -0.06,      0.73,      0.30,     -0.88,\n",
            "              0.76,     -0.91,     -0.62,      0.67,     -0.88,      0.84,     -0.84,     -0.87,      0.40,      0.85,     -0.62,     -0.88,\n",
            "             -0.92,     -0.77,      0.82,      0.62,     -0.45,      0.89,     -0.86,     -0.25,     -0.84,     -0.37,     -0.87,      0.90,\n",
            "              0.76,      0.85,     -0.77,      0.48,     -0.89,     -0.74,      0.24,     -0.92,      0.94,      0.92,      0.82,     -0.80,\n",
            "              0.56,     -0.92,      0.09,     -0.88,      0.41,      0.90,     -0.86,      0.04,      0.92,     -0.46,      0.59,      0.92,\n",
            "              0.89,      0.70,     -0.75,      0.58]], device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 4 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_4 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.88, -0.89, -0.26, -0.70, -0.54,  0.70,  0.48,  0.95, -0.93, -0.89, -0.76,  0.75, -0.04,  0.93, -0.62, -0.92, -0.73, -0.75,  0.63,  0.14,\n",
            "         -0.83, -0.79,  0.46,  0.70, -0.64,  0.76, -0.92,  0.88, -0.91,  0.85,  0.66, -0.89,  0.86,  0.89, -0.20, -0.67, -0.81,  0.91,  0.93,  0.45,\n",
            "         -0.57,  0.28, -0.64,  0.86, -0.31,  0.72,  0.33, -0.58,  0.80, -0.93, -0.67,  0.68, -0.78,  0.62, -0.77, -0.97,  0.57,  0.94, -0.92, -0.25,\n",
            "         -0.88, -0.79,  0.77,  0.59, -0.75,  0.96, -0.65, -0.72, -0.78,  0.05, -0.80,  0.96,  0.75,  0.91, -0.57,  0.69, -0.93, -0.64,  0.39,  0.07,\n",
            "          0.86,  0.88,  0.58, -0.59,  0.54, -0.86, -0.51, -0.63,  0.18,  0.78, -0.93,  0.59,  0.88, -0.86,  0.78,  0.93,  0.89,  0.78, -0.82,  0.33]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 5 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_5 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.92, -0.82,  0.11, -0.83, -0.82,  0.64,  0.45,  0.86, -0.85, -0.95, -0.86,  0.68, -0.04,  0.61, -0.68, -0.89, -0.82, -0.88,  0.76,  0.55,\n",
            "         -0.70, -0.83,  0.44,  0.36, -0.61,  0.82, -0.92,  0.93, -0.79,  0.91,  0.81, -0.66,  0.88,  0.64, -0.70, -0.34, -0.82,  0.90,  0.88,  0.80,\n",
            "         -0.75, -0.43, -0.64,  0.60,  0.22,  0.71,  0.49, -0.23,  0.89, -0.93, -0.83,  0.59, -0.90,  0.82, -0.58, -0.87,  0.70,  0.97, -0.71, -0.68,\n",
            "         -0.95, -0.63,  0.89,  0.76, -0.69,  0.75, -0.84, -0.75, -0.88,  0.52, -0.77,  0.84,  0.88,  0.60, -0.75,  0.68, -0.68, -0.89,  0.46,  0.57,\n",
            "          0.64,  0.79,  0.53, -0.64,  0.81, -0.91, -0.75, -0.76,  0.68,  0.85, -0.77,  0.58,  0.69, -0.94,  0.76,  0.86,  0.81,  0.80, -0.86,  0.70]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 6 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_6 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.99, -0.96,  0.09, -0.95, -0.96,  0.94,  0.95,  0.97, -0.97, -0.98, -0.91,  0.61, -0.50,  0.98, -0.87, -0.93, -0.98, -0.99,  0.98,  0.60,\n",
            "         -0.95, -0.93,  0.41,  0.76, -0.96,  0.98, -0.98,  0.96, -0.91,  0.98,  0.95, -0.99,  0.96,  0.98, -0.83, -0.66, -0.97,  0.97,  0.98,  0.92,\n",
            "         -0.98, -0.69, -0.93,  0.97,  0.42,  0.94,  0.80, -0.96,  0.93, -0.98, -0.96,  0.96, -0.98,  0.97, -0.93, -0.96,  0.90,  0.95, -0.78, -0.94,\n",
            "         -0.98, -0.92,  0.97,  0.93, -0.82,  0.96, -0.98, -0.84, -0.99,  0.60, -0.97,  0.99,  0.93,  0.98, -0.97,  0.79, -0.97, -0.96,  0.89,  0.83,\n",
            "          0.95,  0.99,  0.91, -0.91,  0.89, -0.99, -0.92, -0.96,  0.82,  0.95, -0.96,  0.76,  0.97, -0.95,  0.97,  0.98,  0.98,  0.90, -0.98,  0.88]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 7 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_7 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.99, -0.98,  0.29, -0.98, -0.98,  0.97,  0.97,  0.99, -0.98, -0.99, -0.95,  0.70, -0.82,  0.99, -0.93, -0.96, -0.99, -1.00,  0.99,  0.80,\n",
            "         -0.97, -0.96,  0.41,  0.93, -0.98,  0.99, -0.99,  0.98, -0.96,  0.99,  0.96, -0.99,  0.97,  0.99, -0.91, -0.81, -0.98,  0.98,  0.99,  0.97,\n",
            "         -0.99, -0.86, -0.98,  0.98,  0.50,  0.98,  0.90, -0.98,  0.95, -0.99, -0.99,  0.98, -0.99,  0.99, -0.97, -0.98,  0.96,  0.97, -0.88, -0.98,\n",
            "         -0.99, -0.95,  0.98,  0.96, -0.88,  0.98, -1.00, -0.91, -0.99,  0.74, -0.98,  1.00,  0.96,  0.99, -0.99,  0.84, -0.98, -0.98,  0.92,  0.95,\n",
            "          0.99,  1.00,  0.98, -0.96,  0.95, -0.99, -0.97, -0.97,  0.90,  0.98, -0.98,  0.87,  0.99, -0.97,  0.99,  0.98,  0.99,  0.94, -0.99,  0.94]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 8 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_8 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.99, -0.99,  0.51, -0.98, -0.98,  0.98,  0.97,  0.99, -0.99, -0.99, -0.96,  0.72, -0.94,  0.99, -0.94, -0.96, -0.99, -1.00,  0.99,  0.89,\n",
            "         -0.98, -0.97,  0.40,  0.98, -0.98,  0.99, -0.99,  0.98, -0.96,  1.00,  0.96, -0.99,  0.98,  0.99, -0.94, -0.89, -0.99,  0.99,  0.99,  0.98,\n",
            "         -1.00, -0.94, -0.99,  0.99,  0.52,  0.98,  0.94, -0.99,  0.96, -0.99, -0.99,  0.98, -0.99,  0.99, -0.98, -0.98,  0.97,  0.97, -0.90, -0.99,\n",
            "         -0.99, -0.96,  0.98,  0.97, -0.89,  0.98, -1.00, -0.93, -1.00,  0.84, -0.98,  1.00,  0.97,  0.99, -1.00,  0.84, -0.99, -0.99,  0.93,  0.98,\n",
            "          0.99,  1.00,  0.99, -0.97,  0.96, -0.99, -0.98, -0.97,  0.95,  0.99, -0.98,  0.92,  0.99, -0.98,  0.99,  0.99,  0.99,  0.95, -0.99,  0.95]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 9 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_9 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.94, -0.98,  0.74, -0.89, -0.67,  0.97,  0.91,  0.89, -0.99, -0.73, -0.97,  0.73, -0.84,  0.98, -0.83, -0.78, -0.82, -0.87,  0.83,  0.83,\n",
            "         -0.78, -0.89,  0.77,  0.95, -0.95,  0.89, -0.98,  0.94, -0.99,  0.95,  0.91, -0.88,  0.94,  0.94, -0.87, -0.93, -0.99,  0.58,  0.97,  0.97,\n",
            "         -0.98, -0.90, -0.94,  0.92,  0.52,  0.78,  0.62, -0.98,  0.99, -0.97, -0.97,  0.93, -0.96,  0.95, -0.94, -0.90,  0.96,  0.92, -0.96, -0.75,\n",
            "         -0.96, -0.97,  0.92,  0.87, -0.94,  0.93, -0.84, -0.93, -0.97,  0.94, -0.82,  0.95,  0.97,  0.98, -0.95,  0.50, -0.98, -0.93,  0.93,  0.89,\n",
            "          0.87,  0.99,  0.94, -0.79,  0.99, -0.99, -0.98, -0.64,  0.74,  0.89, -0.99,  0.93,  0.96, -0.93,  0.93,  0.97,  0.94,  0.93, -0.87,  0.74]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 10 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_10 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.73, -0.95,  0.73, -0.81, -0.93,  0.86,  0.69,  0.88, -0.59, -0.80, -0.93,  0.89, -0.64,  0.96, -0.82, -0.97, -0.92, -0.93,  0.89,  0.25,\n",
            "         -0.89, -0.89,  0.36,  0.78, -0.89,  0.68, -0.89,  0.98, -0.78,  0.92,  0.81, -0.94,  0.90,  0.85, -0.98, -0.79, -0.61,  0.89,  0.97,  0.90,\n",
            "         -0.77, -0.73, -0.85,  0.98,  0.78,  0.78,  0.73, -0.92,  0.73, -0.97, -0.87,  0.73, -0.72,  0.67, -0.77, -0.84,  0.92,  0.96, -0.79, -0.87,\n",
            "         -0.92, -0.96,  0.71,  0.83, -0.87,  0.83, -0.93, -0.59, -0.84,  0.91, -0.85,  0.83,  0.94,  0.90, -0.83,  0.62, -0.70, -0.93,  0.94,  0.94,\n",
            "          0.95,  0.88,  0.98, -0.69,  0.82, -0.94, -0.99, -0.78,  0.59,  0.86, -0.89,  0.65,  0.89, -0.92,  0.78,  0.93,  0.76,  0.73, -0.45,  0.85]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 11 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_11 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.75, -0.93,  0.47, -0.71, -0.96,  0.89,  0.82,  0.97, -0.97, -0.98, -0.96,  0.94, -0.88,  0.98, -0.68, -0.95, -0.98, -0.97,  0.98,  0.66,\n",
            "         -0.93, -0.86,  0.23,  0.87, -0.97,  0.39, -0.83,  0.91, -0.80,  0.94,  0.95, -0.96,  0.75,  0.98, -0.95, -0.38, -0.93,  0.95,  0.96,  0.90,\n",
            "         -0.94, -0.92, -0.88,  0.96,  0.60,  0.97,  0.92, -0.97,  0.98, -0.93, -0.96,  0.91, -0.91,  0.94, -0.97, -0.85,  0.96,  0.78, -0.86, -0.94,\n",
            "         -0.97, -0.96,  0.88,  0.84, -0.82,  0.77, -0.93, -0.86, -0.98,  0.96, -0.98,  0.96,  0.94,  0.93, -0.87,  0.57, -0.93, -0.98,  0.96,  0.70,\n",
            "          0.95,  0.97,  0.99, -0.91,  0.94, -0.96, -0.95, -0.93,  0.81,  0.74, -0.83,  0.84,  0.74, -0.91,  0.91,  0.96,  0.72,  0.92, -0.96,  0.72]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 12 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_12 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.77, -0.91,  0.71, -0.91, -0.93,  0.65,  0.82,  0.81, -0.97, -0.99, -0.96,  0.86, -0.62,  0.98, -0.92, -0.72, -0.94, -0.91,  0.97,  0.75,\n",
            "         -0.81, -0.64, -0.49,  0.84, -0.94,  0.73, -0.83,  0.91, -0.88,  0.83,  0.95, -0.90,  0.59,  0.92, -0.96, -0.70, -0.66,  0.66,  0.97,  0.74,\n",
            "         -0.95, -0.74, -0.85,  0.77,  0.50,  0.89,  0.83, -0.93,  0.86, -0.89, -0.98,  0.35, -0.96,  0.82, -0.88, -0.95,  0.84,  0.96, -0.88, -0.91,\n",
            "         -0.58, -0.93,  0.30,  0.93, -0.91,  0.77, -0.93, -0.65, -0.98,  0.80, -0.90,  0.98,  0.51,  0.73, -0.83,  0.18, -0.94, -0.94,  0.92,  0.74,\n",
            "          0.91,  0.82,  0.94, -0.85,  0.78, -0.91, -0.84, -0.55,  0.69,  0.93, -0.99,  0.76,  0.66, -0.92,  0.82,  0.65,  0.76,  0.94, -0.96,  0.52]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 13 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_13 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.95, -0.86,  0.90, -0.93, -0.89,  0.84,  0.61,  0.82, -0.95, -0.84, -0.73,  0.75, -0.62,  0.90, -0.77, -0.71, -0.85, -0.74,  0.94,  0.79,\n",
            "         -0.76, -0.66, -0.25,  0.94, -0.94,  0.66, -0.87,  0.90, -0.81,  0.87,  0.86, -0.96,  0.85,  0.66, -0.65, -0.59, -0.91,  0.82,  0.86,  0.62,\n",
            "         -0.74, -0.89, -0.92,  0.82,  0.61,  0.65,  0.85, -0.83,  0.91, -0.89, -0.67,  0.78, -0.76,  0.87, -0.88, -0.86,  0.91,  0.86, -0.83, -0.57,\n",
            "         -0.85, -0.70,  0.86,  0.77, -0.76,  0.88, -0.91, -0.77, -0.97,  0.84, -0.72,  0.82,  0.72,  0.62, -0.92, -0.06, -0.85, -0.96,  0.32,  0.79,\n",
            "          0.86,  0.92,  0.98, -0.80,  0.86, -0.92, -0.82, -0.74,  0.78,  0.82, -0.98,  0.89,  0.79, -0.88,  0.41,  0.77,  0.76,  0.92, -0.94,  0.73]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 14 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_14 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.88, -0.06,  0.37, -0.88, -0.88,  0.66,  0.91,  0.91, -0.76, -0.80, -0.91,  0.61, -0.27,  0.91, -0.87, -0.90, -1.00, -0.85,  0.97,  0.88,\n",
            "         -0.95, -0.04, -0.52,  0.82, -0.93,  0.57, -0.85,  0.88, -0.51,  0.92,  0.54, -0.83,  0.47,  0.91, -0.90, -0.93, -0.92,  0.87,  0.96,  0.62,\n",
            "         -0.93, -0.94, -0.92,  0.96,  0.66,  0.23,  0.96, -0.96,  0.76, -0.94, -0.77,  0.83, -0.72,  0.85, -0.98, -0.75,  0.94,  0.87, -0.69, -0.93,\n",
            "         -0.99, -0.78,  0.75,  0.83, -0.89,  0.74, -0.86, -0.91, -0.97,  0.86, -0.94,  0.73,  0.98,  0.37, -0.88, -0.26, -0.32, -0.96,  0.79,  0.52,\n",
            "          0.91,  0.96,  0.88, -0.67,  0.90, -0.54, -0.86, -0.62,  0.80,  0.96, -0.95,  0.84,  0.72, -0.86,  0.70,  0.71,  0.53,  0.71, -0.86,  0.86]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Feeding word 15 of the sentence with length 15 \n",
            "\n",
            "Hidden state -- h_15 -- for batch size of 1: \n",
            "\n",
            "tensor([[ 0.96,  0.43,  0.62, -0.90, -0.77,  0.82,  0.98,  0.26, -1.00, -0.99, -0.80,  0.90, -0.64,  0.98, -0.70, -0.93, -0.74, -0.98,  0.90,  0.92,\n",
            "         -0.95,  0.44, -0.91,  0.56, -0.99,  0.59, -0.43,  0.96, -0.97,  0.93,  0.99, -0.98,  0.92,  0.93, -0.96, -0.80, -0.98,  0.95,  0.97,  0.47,\n",
            "         -1.00, -0.95, -0.74,  1.00,  0.97, -0.13,  0.78, -0.93,  0.97, -0.99, -0.86,  0.97, -1.00,  1.00, -0.98, -1.00,  0.93,  0.97, -0.71, -0.70,\n",
            "         -0.97, -0.97,  0.54,  0.96, -0.98,  0.75, -0.89, -0.98, -0.98,  0.91, -0.99,  0.76,  0.97,  0.99, -0.82,  0.56, -0.94, -0.99,  0.99,  0.49,\n",
            "          0.88,  0.98,  0.96, -0.77,  0.92, -0.99, -0.32, -0.89,  0.64,  0.94, -0.99,  0.97,  0.86, -0.79,  0.99,  0.72,  0.84,  0.86, -0.99,  0.78]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Output of Encoder : \n",
            "******************\n",
            "  tensor([[ 0.96,  0.43,  0.62, -0.90, -0.77,  0.82,  0.98,  0.26, -1.00, -0.99, -0.80,  0.90, -0.64,  0.98, -0.70, -0.93, -0.74, -0.98,  0.90,  0.92,\n",
            "         -0.95,  0.44, -0.91,  0.56, -0.99,  0.59, -0.43,  0.96, -0.97,  0.93,  0.99, -0.98,  0.92,  0.93, -0.96, -0.80, -0.98,  0.95,  0.97,  0.47,\n",
            "         -1.00, -0.95, -0.74,  1.00,  0.97, -0.13,  0.78, -0.93,  0.97, -0.99, -0.86,  0.97, -1.00,  1.00, -0.98, -1.00,  0.93,  0.97, -0.71, -0.70,\n",
            "         -0.97, -0.97,  0.54,  0.96, -0.98,  0.75, -0.89, -0.98, -0.98,  0.91, -0.99,  0.76,  0.97,  0.99, -0.82,  0.56, -0.94, -0.99,  0.99,  0.49,\n",
            "          0.88,  0.98,  0.96, -0.77,  0.92, -0.99, -0.32, -0.89,  0.64,  0.94, -0.99,  0.97,  0.86, -0.79,  0.99,  0.72,  0.84,  0.86, -0.99,  0.78]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 100])\n",
            "\n",
            "Output of Decoder : \n",
            "******************\n",
            " tensor([[ 0.43,  0.68,  0.48,  0.69, -0.58, -0.52, -0.34,  0.65, -0.00, -0.41,  0.08, -0.61, -0.63,  0.60,  0.37, -0.56,  0.75, -0.10, -0.52,  0.31,\n",
            "          0.56,  0.68, -0.43, -0.64,  0.45, -0.04, -0.49, -0.63, -0.34, -0.55, -0.52, -0.66,  0.16, -0.53, -0.21, -0.28, -0.12, -0.62, -0.90, -0.40,\n",
            "          0.80,  0.51, -0.57,  0.80, -0.30,  0.57, -0.45, -0.31,  0.24,  0.43, -0.49,  0.29, -0.45,  0.65, -0.73, -0.54, -0.61,  0.56,  0.55,  0.72,\n",
            "          0.59,  0.51,  0.72,  0.39,  0.64, -0.56,  0.70,  0.65,  0.74,  0.34,  0.61,  0.39,  0.13,  0.78,  0.13,  0.32, -0.36,  0.48, -0.74,  0.39,\n",
            "         -0.37,  0.53, -0.74, -0.16, -0.70, -0.03, -0.74, -0.77, -0.82, -0.66,  0.67,  0.82, -0.66,  0.63, -0.63,  0.35, -0.05, -0.70,  0.10,  0.52,\n",
            "         -0.14,  0.53,  0.74, -0.18,  0.53,  0.13, -0.62,  0.55,  0.71, -0.76, -0.35,  0.64, -0.68,  0.68, -0.56, -0.45, -0.33,  0.73,  0.50, -0.14,\n",
            "          0.32,  0.04, -0.60, -0.56, -0.70,  0.37, -0.61, -0.29,  0.65,  0.37,  0.31,  0.11, -0.10,  0.33, -0.09,  0.59, -0.82, -0.65, -0.56,  0.44,\n",
            "         -0.52, -0.53,  0.31,  0.70, -0.58, -0.69,  0.63, -0.77,  0.32,  0.12]], device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>) torch.Size([1, 150])\n",
            "Sentiment Classified as Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq6LgQqy4BWD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}